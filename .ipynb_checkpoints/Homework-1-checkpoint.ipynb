{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import random\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "Generate Rankings of Relevance for E and P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of possible rankings:  59049\n"
     ]
    }
   ],
   "source": [
    "#Generating all possible combinations of relevance,\n",
    "#where  0 - N, 1 - R, 2 - HR\n",
    "possible_rankings = itertools.product([0,1,2], repeat=5)\n",
    "P = [list(i) for i in possible_rankings]\n",
    "E = P[:]\n",
    "\n",
    "#Constructing all possible pairs\n",
    "L = []\n",
    "for item1 in P:\n",
    "    for item2 in E:\n",
    "        pair = []\n",
    "        pair.append(item1)\n",
    "        pair.append(item2)\n",
    "        L.append(pair)\n",
    "print \"Number of possible rankings: \", len(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "Implement Evaluation Measures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:\n",
      " Rankings:  [[0, 0, 0, 1, 1], [2, 1, 0, 1, 1]]\n",
      " Precision@4:  [0.25, 0.75]\n",
      " DCG@4:  [0.0, 4.061606311644851]\n",
      " RBP:  [0.1024, 0.6623999999999999]\n"
     ]
    }
   ],
   "source": [
    "def precision(res, k):\n",
    "    counter = 0\n",
    "    for i in range(k):\n",
    "        if res[i] != 0:\n",
    "            counter += 1\n",
    "    return 1.0*counter / k\n",
    "\n",
    "def DCG(res, k):\n",
    "    sum = 0\n",
    "    for r in range(1,k+1):\n",
    "        sum += (2**res[r-1] - 1)/math.log(1+r,2)\n",
    "    return sum\n",
    "\n",
    "def RBP(res, theta = 0.8):\n",
    "    sum = 0\n",
    "    for k in range(1, len(res)):\n",
    "        sum += res[k-1] * theta**(k-1)*(1 - theta)\n",
    "    return sum\n",
    "\n",
    "N=1165\n",
    "print \"Example:\"\n",
    "print \" Rankings: \", L[N]\n",
    "print \" Precision@4: \", [precision(L[N][0],k = 4), precision(L[N][1],k = 4)]\n",
    "print \" DCG@4: \", [DCG(L[N][0],k = 3),DCG(L[N][1],k = 4)]\n",
    "print \" RBP: \", [RBP(L[N][0]), RBP(L[N][1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3\n",
    " Calculate the 𝛥measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: \n",
      " Rankings:  [[0, 0, 2, 2, 1], [2, 0, 2, 2, 2]]\n",
      " DCG difference:  3.77370561447\n",
      "Number of pairs for which E outperforms P for different measures:\n",
      " Precision: 21762\n",
      " DCG: 29376\n",
      " RBP: 29160\n"
     ]
    }
   ],
   "source": [
    "def delta_measure(pairs, measure, k=5):\n",
    "    result = []\n",
    "    for pair in pairs:\n",
    "        if measure == \"precision\":\n",
    "            P = precision(pair[0], k)\n",
    "            E = precision(pair[1], k)\n",
    "        \n",
    "        if measure == \"DCG\":\n",
    "            P = DCG(pair[0], k)\n",
    "            E = DCG(pair[1], k)\n",
    "            \n",
    "        if measure == \"RBP\":\n",
    "            P = RBP(pair[0])\n",
    "            E = RBP(pair[1])\n",
    "         \n",
    "        diff = E - P\n",
    "        \n",
    "        if diff > 0:\n",
    "            result.append([pair, diff])\n",
    "            \n",
    "    return result\n",
    "\n",
    "dcg_res = delta_measure(L, \"DCG\")\n",
    "prec_res = delta_measure(L, \"precision\")\n",
    "rbp_res = delta_measure(L, \"RBP\")\n",
    "\n",
    "N=5432\n",
    "print \"Example: \"\n",
    "print \" Rankings: \", res[N][0]\n",
    "print \" DCG difference: \", res[N][1]\n",
    "\n",
    "print \"Number of pairs for which E outperforms P for different measures:\"\n",
    "print \" Precision:\", len(prec_res)\n",
    "print \" DCG:\", len(dcg_res)\n",
    "print \" RBP:\", len(rbp_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4\n",
    "Implement Interleaving\n",
    "\n",
    "In our implementations of the generic Team Draft Interleaving and Probabilistic Interleaving, we also consider overlapping documents between the two rankings. To find which documents are the same, we are comparing the labels of the documents.\n",
    "\n",
    "To make use of this generic algorithm with our rankings, that have relevance as labels, we have to alter the labels so that each one of them is unique. We do that by appending a unique number next to the relevance. For example, the rankings pair:\n",
    "\n",
    "[0, 0, 2, 2, 1], [2, 0, 2, 2, 2]\n",
    "\n",
    "becomes\n",
    "\n",
    "[00, 01, 22, 23, 14], [25, 06, 27, 28, 29]\n",
    "\n",
    "In this way, we make sure that there are no overlapping documents between the two rankings, as is required by Note 5 a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--TeamDraft Interleaving--\n",
      "Rankings:  [[0, 0, 0, 1, 2], [0, 0, 1, 2, 2]]\n",
      "-RCM:\n",
      " Interleaved: [0, 0, 0, 0, 0, 1, 1, 2, 2, 2]\n",
      " Assignments: [1, 0, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      " Clicks: []\n",
      " Comparison: 0\n",
      "-SDCM:\n",
      " Interleaved: [0, 0, 0, 0, 1, 0, 2, 1, 2, 2]\n",
      " Assignments: [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      " Clicks: [4]\n",
      " Comparison: -1\n"
     ]
    }
   ],
   "source": [
    "#Team Draft Interleaving\n",
    "\n",
    "#make all labels of the selected pair of rankings unique\n",
    "def preprocess(pair):\n",
    "    c = 0\n",
    "    new_pair = ([], [])\n",
    "    for i in range(2):\n",
    "        for item in pair[i]:\n",
    "            new_pair[i].append(str(item)+ str(c))\n",
    "            c+=1\n",
    "    return new_pair\n",
    "\n",
    "\n",
    "def outcome_function(c,a):\n",
    "    counters = [0, 0]\n",
    "    for i in c:\n",
    "        counters[a[i]]+=1\n",
    "    return numpy.sign(counters[0]-counters[1])\n",
    "\n",
    "\n",
    "#generate a list of random clicks\n",
    "def get_clicks(l, number):\n",
    "    ind_order = range(len(l))\n",
    "    random.shuffle(ind_order)\n",
    "    return ind_order[:number]\n",
    "\n",
    "#RCM stands for Random Click Model, in which a document has a probability 'r' of being clicked (r = parameters[0])\n",
    "#SDCM stands for Simple Dependent Click Model (lambdas = parameters)\n",
    "#default means that a certain amount of random docs will be clicked at random(#clicked docs = parameters[0], default is 2)\n",
    "def simulate_clicks(interleaved,  click_model = \"default\", parameters = [2], clicks = None):\n",
    "    if clicks == None:\n",
    "        if click_model == \"default\":\n",
    "            clicks = get_clicks(interleaved, parameters[0])\n",
    "        if click_model == \"RCM\":\n",
    "            clicks = RCM(interleaved,parameters[0])\n",
    "        if click_model == \"SDCM\":\n",
    "            attr  = get_attractiveness(interleaved)\n",
    "            clicks = SDCM(attr ,parameters)\n",
    "    \n",
    "    return clicks\n",
    "\n",
    "#a) create the interleaving list\n",
    "def team_draft_interleave(pair):\n",
    "    lists = [pair[0][:],pair[1][:]]\n",
    "    l = []\n",
    "    a = []\n",
    "    while lists[0] or lists[1]:\n",
    "        if lists[0] and lists[1]:\n",
    "            first = random.randint(0,1)\n",
    "        elif lists[0]:\n",
    "            first = 0\n",
    "        else:\n",
    "            first = 1\n",
    "        second = int(math.fabs(first-1))\n",
    "\n",
    "        #pick from the first list\n",
    "        doc = lists[first][0]\n",
    "        l.append(doc)\n",
    "        a.append(first)\n",
    "        #delete the doc from the first list (top element) and the second list\n",
    "        del lists[first][0]   \n",
    "        try:\n",
    "            lists[second].remove(doc)     \n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        #pick from the second list\n",
    "        if lists[second]:\n",
    "            doc = lists[second][0]\n",
    "            l.append(doc)\n",
    "            a.append(second) \n",
    "            #delete the doc from the second list (top element) and the first list\n",
    "            del lists[second][0]        \n",
    "            try:\n",
    "                lists[first].remove(doc)    \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    res = []\n",
    "    for i in range(len(l)):\n",
    "        res.append([l[i],a[i]])\n",
    "    return res #l,a\n",
    "    \n",
    "#b) evaluate the interleaved list\n",
    "def team_draft_evaluate(interleaved, clicks):\n",
    "    l, a = zip(*interleaved)\n",
    "    o = outcome_function(clicks,a)\n",
    "    return o\n",
    "\n",
    "def team_draft(pair, click_model = \"default\", parameters = [2], clicks = None):\n",
    "    interleaved = team_draft_interleave(pair)\n",
    "    clicks = simulate_clicks(interleaved,  click_model = click_model, parameters = parameters, clicks = clicks)\n",
    "    l, a = zip(*interleaved)\n",
    "    evaluation = team_draft_evaluate(interleaved, clicks)\n",
    "    print \" Interleaved:\", [int(i[0]) for i in l]\n",
    "    print \" Assignments:\", list(a)\n",
    "    print \" Clicks:\", clicks\n",
    "    print \" Comparison:\", evaluation\n",
    "    return evaluation\n",
    "\n",
    "N=1232\n",
    "print \"--TeamDraft Interleaving--\"\n",
    "print \"Rankings: \", L[N]\n",
    "#res = team_draft(preprocess(L[N]))\n",
    "print \"-RCM:\"\n",
    "res = team_draft(preprocess(L[N]),click_model = \"RCM\", parameters = [r])\n",
    "print \"-SDCM:\"\n",
    "res = team_draft(preprocess(L[N]),click_model = \"SDCM\", parameters = lambdas)\n",
    "#print \" Evaluation: \", res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilistic Interleaving\n",
      "Example:\n",
      " Rankings:  [[0, 0, 1, 2, 2], [2, 1, 1, 1, 2]]\n",
      "[('16', 1), ('01', 0), ('25', 1), ('17', 1), ('29', 1), ('18', 1), ('00', 0), ('12', 0), ('24', 0), ('23', 0)]\n",
      "[0, 1, 2, 6]\n",
      " Evaluation:  0\n"
     ]
    }
   ],
   "source": [
    "#Probabilistic Interleaving\n",
    "\n",
    "#a) create the interleaving list\n",
    "def prob_interleave(pair, tau = 3):\n",
    "    #add to each entry of a ranking the id of the ranking it is from\n",
    "    lists = [zip(pair[0],[0]*len(pair[0])), zip(pair[1],[1]*len(pair[1]))]\n",
    "    result = []\n",
    "    sum = 0\n",
    "    for i in range(0, len(lists[0])):\n",
    "        sum += 1.0/((i+1)**tau)\n",
    "    p = [[(1.0/((i+1)**tau))/sum for i in range(0, len(lists[0]))], [(1.0/((i+1)**tau))/sum for i in range(0, len(lists[0]))]]\n",
    "\n",
    "    counter = [len(lists[0]),len(lists[1])] # the number of documents left in l1 and l2 \n",
    "    \n",
    "    #construct the interleaving by iteratively\n",
    "    #adding a pair of entries to the resulting list\n",
    "    while counter[0] > 0 or counter[1] > 0:\n",
    "        #select the id of the ranking to draw an entry from\n",
    "        if counter[0] > 0 and counter[1] > 0:\n",
    "            selected = random.randint(0,1)\n",
    "        elif counter[0] > 0:\n",
    "            selected = 0\n",
    "        else:\n",
    "            selected = 1\n",
    "        other_ind = int(math.fabs(selected-1))\n",
    "        \n",
    "        #select a new entry with the softmax\n",
    "        doc_index = numpy.random.choice(range(len(lists[selected])),1,p=p[selected])[0]\n",
    "        doc = lists[selected][doc_index]\n",
    "        result.append(doc)\n",
    "        \n",
    "        #renormalize the softmax probabilities (do not renormalize if there are no documents left)\n",
    "        oldp = p[selected][doc_index]\n",
    "        p[selected][doc_index] = 0\n",
    "        counter[selected] -= 1\n",
    "        if counter[selected] > 0: \n",
    "            p[selected] = [val/(1.0-oldp) for val in p[selected]]\n",
    "        \n",
    "        doc_l = list(doc)\n",
    "        doc_l[1] = other_ind\n",
    "        doc = (doc_l[0], doc_l[1])\n",
    "        if doc in lists[other_ind]:\n",
    "            ind = lists[other_ind].index(doc)\n",
    "            oldp = p[other_ind][ind]\n",
    "            p[other_ind][ind] = 0\n",
    "            counter[other_ind] -= 1\n",
    "            if counter[other_ind] > 0:\n",
    "                p[other_ind] = [val/(1.0-oldp) for val in p[other_ind]]\n",
    "        \n",
    "        \n",
    "    return result\n",
    "        \n",
    "    \n",
    "#b) evaluate the interleaved list\n",
    "def prob_evaluate(interleaved, clicks):\n",
    "    return team_draft_evaluate(interleaved, clicks)\n",
    "   \n",
    "\n",
    "def prob(pair,  click_model = \"default\", parameters = [2], clicks = None):\n",
    "    interleaved = prob_interleave(pair) \n",
    "    print interleaved\n",
    "    clicks = simulate_clicks(interleaved,  click_model = click_model, parameters = parameters, clicks = clicks)\n",
    "    print clicks\n",
    "    return prob_evaluate(interleaved, clicks)\n",
    "\n",
    "    \n",
    "N=4334\n",
    "print \"Probabilistic Interleaving\"\n",
    "print \"Example:\"\n",
    "print \" Rankings: \", L[N]\n",
    "pair = preprocess(L[N])\n",
    "# print pair\n",
    "res = prob(pair,click_model = \"RCM\", parameters = [r])\n",
    "print \" Evaluation: \", res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5\n",
    "Implement User Clicks Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['7', '103', '51', '92', '43', '12', '73', '69', '27', '105'], []]\n",
      "[['1625', '1627', '1623', '1626', '1624', '1622', '1619', '1621', '1620', '1618'], []]\n",
      "[['2094', '2091', '2087', '2089', '2093', '2088', '2090', '2092', '2095', '2086'], []]\n",
      "[['1625', '1627', '1623', '1626', '1624', '1622', '1619', '1621', '1620', '1618'], []]\n",
      "[['17562', '1627', '1626', '1623', '2091', '17559', '17563', '17558', '17561', '17560'], ['17562', '1627', '1626']]\n"
     ]
    }
   ],
   "source": [
    "table = []\n",
    "with open('YandexRelPredChallenge.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.split()\n",
    "        table.append(line)\n",
    "f.closed\n",
    "\n",
    "sum = 0\n",
    "S = []\n",
    "for line in table:\n",
    "    if(line[2]) == 'Q':\n",
    "        S.append([])\n",
    "        S[-1].append(line[5:])\n",
    "        S[-1].append([])\n",
    "    if(line[2]) == 'C':\n",
    "        c = line[-1] \n",
    "        for i in range(-1,-len(S) - 1, -1): #attribute the click to the last query that had this document as a result\n",
    "            if c in S[i][0]:\n",
    "                S[i][1].append(c)\n",
    "                break;\n",
    "\n",
    "for i in range(5):\n",
    "    print S[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RCM parameter: 0.126312951327\n"
     ]
    }
   ],
   "source": [
    "def RCM_parameter(S):\n",
    "    sum1 = 0\n",
    "    sum2 = 0\n",
    "    for s in S:\n",
    "        clicks = set()\n",
    "        for c in s[1]:\n",
    "            clicks.add(c)\n",
    "        sum1 += len(clicks)\n",
    "\n",
    "        sum2 += len(s[0])\n",
    "\n",
    "    return 1.0*sum1/sum2\n",
    "\n",
    "def RCM(l, r):\n",
    "    c = []\n",
    "    for i in range(len(l)):\n",
    "        p = random.uniform(0, 1)\n",
    "        if p < r:\n",
    "            c.append(i)\n",
    "    return c\n",
    "\n",
    "r = RCM_parameter(S)\n",
    "print \"RCM parameter:\", r\n",
    "\n",
    "# for i in range(10):\n",
    "#     print RCM([1,2,3,4,5,6,7,8,9,0], r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDCM parameters (lambdas):\n",
      " l0 = 0.319429312581\n",
      " l1 = 0.53782013103\n",
      " l2 = 0.57064311896\n",
      " l3 = 0.583973655324\n",
      " l4 = 0.577966101695\n",
      " l5 = 0.557948717949\n",
      " l6 = 0.554520760574\n",
      " l7 = 0.505861919236\n",
      " l8 = 0.468378506895\n",
      " l9 = 0.227272727273\n"
     ]
    }
   ],
   "source": [
    "def get_Sr(queries, r):\n",
    "    return  filter(lambda query: query[0][r-1] in query[1] , queries)\n",
    "\n",
    "def get_lambda_r(queries, r):\n",
    "    Sr = get_Sr(queries, r)\n",
    "    n = len(Sr)\n",
    "    sum = 0\n",
    "    for s in Sr:\n",
    "        indices = [-1] + [s[0].index(doc1) for doc1 in s[1]]\n",
    "        last_clicked = indices[-1]+1\n",
    "        additive = 0\n",
    "        if last_clicked != r:\n",
    "            additive = 1\n",
    "        sum += additive\n",
    "    return sum/float(len(Sr))\n",
    "        \n",
    "def get_lambdas(queries, maxr=10):\n",
    "    return [get_lambda_r(queries, r) for r in range(1, maxr+1)]\n",
    "\n",
    "def get_attractiveness(interleaved):\n",
    "    rel_attr = {}\n",
    "    rel_attr[0] = 0\n",
    "    rel_attr[1] = 0.7\n",
    "    rel_attr[2] = 0.9\n",
    "    a = []\n",
    "    for doc in interleaved:\n",
    "        rel = int(doc[0][0])\n",
    "        a.append(rel_attr[rel])\n",
    "    return a\n",
    "\n",
    "#get the clicks for the ranked document list, where\n",
    "#'l_r' is the probability of continuing examination when the document at rank 'r' was clicked\n",
    "#'a_u' is the attractiveness of document 'u' for this specific query\n",
    "def SDCM(a_u,l_r):\n",
    "    clicks = []\n",
    "    for i in range(len(a_u)):\n",
    "        p = random.uniform(0,1) #choose if to click\n",
    "        if p < a_u[i]:\n",
    "            clicks.append(i) \n",
    "            p = random.uniform(0,1) #choose if to stop examining\n",
    "            if p < l_r[i]:\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "    return clicks\n",
    "\n",
    "\n",
    "lambdas = get_lambdas(S)\n",
    "print \"SDCM parameters (lambdas):\"\n",
    "for i in range(len(lambdas)):\n",
    "    print (\" l%d =\"%i), lambdas[i]\n",
    "# for i in range(10):\n",
    "#     print SDCM([0.8, 0.9, 0.3, 0.5, 0.6, 0.4], lambdas)#[0.5, 0.6, 0.4, 0.3, 0.2, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Step 6\n",
    "Simulate Interleaving Experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "interleavings = ['TeamDraft', 'Probabilistic']\n",
    "clickModels = ['RCM', 'SDCM']\n",
    "\n",
    "\n",
    "def run_simulation(pair, N):\n",
    "    result = []\n",
    "    for interleaving in interleavings:\n",
    "        int_result = []\n",
    "        \n",
    "        #generate interleaved list\n",
    "        if interleaving == 'TeamDraft':\n",
    "            interleaved = team_draft_interleave(pair)\n",
    "        elif interleaving =='Probabilistic':\n",
    "            interleaved = prob_interleave(pair) \n",
    "            \n",
    "        for clickModel in clickModels:\n",
    "            sum = 0\n",
    "            \n",
    "            #prepare parameters of the selected click model\n",
    "            parameters = []\n",
    "            if clickModel == 'RCM':\n",
    "                parameters = [r]\n",
    "            elif clickModel == 'SDCM':\n",
    "                parameters = lambdas\n",
    "            \n",
    "            #generate N samples\n",
    "            for i in range(N):\n",
    "                #generate clicks according to the selected click model\n",
    "                clicks = simulate_clicks(interleaved,click_model = clickModel, parameters = parameters)\n",
    "\n",
    "                #evaluate the score of the interleaved list with the generated clicks\n",
    "                if interleaving == 'TeamDraft':\n",
    "                    score = team_draft_evaluate(interleaved, clicks)\n",
    "                    if score == -1:\n",
    "                        sum += 1\n",
    "                elif interleaving =='Probabilistic':\n",
    "                    score = prob_evaluate(interleaved, clicks)\n",
    "                    if score == -1:\n",
    "                        sum += 1                    \n",
    "            int_result.append(sum/float(N))\n",
    "        result.append(int_result)\n",
    "        \n",
    "    return result\n",
    "\n",
    "#run the simulation with all possible pairs of relevance\n",
    "def run( N):\n",
    "    result = []\n",
    "    for pair in L:\n",
    "        result.append(run_simulation(preprocess(pair), N))\n",
    "    return result\n",
    "    \n",
    "# run_simulation(preprocess(L[5521]), 3)\n",
    "simulation_results = run(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.random.choice(5, 1, p=[0.1, 0, 0.3, 0.6, 0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
